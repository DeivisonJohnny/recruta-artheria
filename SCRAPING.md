# Scraping do LinkedIn com ScrapingDog

## üìã Vis√£o Geral

A aplica√ß√£o agora implementa scraping real de busca no LinkedIn usando a API do ScrapingDog. O sistema possui fallback autom√°tico para resultados mockados caso a API n√£o esteja dispon√≠vel ou configurada.

## üîß Como Funciona

### 1. Busca de Perfis

A busca funciona em tr√™s etapas:

1. **Constru√ß√£o da Query**
   - Combina profiss√£o, localiza√ß√£o, tecnologias e palavras-chave
   - Cria URL de busca do LinkedIn (`/search/results/people/`)

2. **Scraping com ScrapingDog**
   - Envia a URL para a API do ScrapingDog
   - Usa `dynamic=true` para carregar JavaScript
   - Recebe HTML completo da p√°gina de resultados

3. **Extra√ß√£o de Perfis**
   - Usa regex para encontrar links de perfis (`/in/username`)
   - Remove duplicatas
   - Retorna at√© 20 perfis √∫nicos

### 2. Fallback Autom√°tico

O sistema possui fallback em m√∫ltiplos n√≠veis:

- ‚ùå **Chave API n√£o configurada** ‚Üí Resultados mockados
- ‚ùå **Erro na requisi√ß√£o** ‚Üí Resultados mockados
- ‚ùå **Nenhum perfil encontrado** ‚Üí Resultados mockados
- ‚úÖ **Sucesso** ‚Üí Perfis reais do LinkedIn

## üöÄ Configura√ß√£o

### Pr√©-requisitos

1. Conta ativa no ScrapingDog
2. Chave API v√°lida
3. Cr√©ditos suficientes no plano

### Vari√°veis de Ambiente

No arquivo `.env`:

```env
SCRAPINGDOG_API_KEY="sua-chave-api-aqui"
```

### Custo por Pesquisa

- **Scraping din√¢mico**: ~2-5 cr√©ditos por pesquisa
- **Plano gratuito**: 1.000 cr√©ditos/m√™s
- **Estimativa**: ~200-500 pesquisas/m√™s no plano gratuito

## üìä Limita√ß√µes

### Do LinkedIn

- LinkedIn pode bloquear IPs com muitas requisi√ß√µes
- A estrutura do HTML pode mudar (requer manuten√ß√£o)
- Alguns perfis podem estar protegidos

### Do ScrapingDog

- Limite de requisi√ß√µes por minuto (depende do plano)
- Taxa de sucesso pode variar (70-90%)
- Tempo de resposta: 5-15 segundos por busca

### Da Implementa√ß√£o Atual

- Extra√ß√£o b√°sica (apenas linkedinId e URL)
- N√£o captura nome completo ou headline na busca
- Limite de 20 resultados por pesquisa
- Regex pode n√£o capturar todos os perfis

## üîÑ Fluxo Completo

```
Usu√°rio faz busca
    ‚Üì
Constr√≥i query (profiss√£o + local + tech)
    ‚Üì
Envia para ScrapingDog API
    ‚Üì
ScrapingDog faz scraping do LinkedIn
    ‚Üì
Retorna HTML da p√°gina de resultados
    ‚Üì
Extrai URLs de perfis com regex
    ‚Üì
Salva perfis no banco (cache m√≠nimo)
    ‚Üì
Retorna resultados para o usu√°rio
    ‚Üì
Quando usu√°rio clica em "Ver Detalhes"
    ‚Üì
Busca perfil completo com ScrapingDog Profile API
    ‚Üì
Salva dados completos no banco (cache)
```

## üõ†Ô∏è Melhorias Futuras

### 1. Parser de HTML Robusto
Usar biblioteca como `cheerio` ou `jsdom`:

```bash
npm install cheerio
```

```typescript
import * as cheerio from 'cheerio';

function extractProfilesFromHTML(html: string) {
  const $ = cheerio.load(html);
  const profiles = [];

  $('.entity-result__title-text a').each((i, elem) => {
    const url = $(elem).attr('href');
    const name = $(elem).text().trim();
    // ... extrair mais dados
  });

  return profiles;
}
```

### 2. Rate Limiting
Implementar controle de taxa de requisi√ß√µes:

```typescript
import rateLimit from 'express-rate-limit';

const limiter = rateLimit({
  windowMs: 60 * 1000, // 1 minuto
  max: 5, // 5 requisi√ß√µes por minuto
});
```

### 3. Fila de Processamento
Usar Redis + Bull para processar buscas em background:

```typescript
import Queue from 'bull';

const searchQueue = new Queue('linkedin-search');

searchQueue.process(async (job) => {
  return await searchLinkedInProfiles(job.data.query);
});
```

### 4. Cache de Buscas
Cachear resultados de buscas id√™nticas:

```typescript
const cacheKey = `search:${profession}:${location}:${tech}`;
const cached = await redis.get(cacheKey);

if (cached) {
  return JSON.parse(cached);
}

// ... fazer busca
await redis.setex(cacheKey, 3600, JSON.stringify(results));
```

### 5. Retry Logic
Tentar novamente em caso de falha:

```typescript
async function searchWithRetry(query: string, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await searchLinkedInProfiles(query);
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await sleep(1000 * (i + 1)); // Backoff exponencial
    }
  }
}
```

## üîê Considera√ß√µes de Seguran√ßa

1. **N√£o exponha a chave API** no frontend
2. **Rate limiting** para prevenir abuso
3. **Valida√ß√£o de input** para prevenir injection
4. **Logs de uso** para monitorar custos
5. **HTTPS obrigat√≥rio** em produ√ß√£o

## üìù Logs e Monitoramento

O sistema j√° loga eventos importantes:

```
‚úÖ ScrapingDog API key configurada
‚ö†Ô∏è  Nenhum perfil encontrado, usando mock
‚ùå Erro na busca: [detalhes do erro]
```

Recomenda√ß√µes:
- Usar servi√ßo de logging (Datadog, LogRocket)
- Alertas para taxa de erro > 50%
- Dashboard de uso e custos

## üß™ Testando

Para testar o scraping real:

1. Configure a chave API no `.env`
2. Execute a aplica√ß√£o: `npm run dev`
3. Fa√ßa uma busca na interface
4. Verifique os logs no terminal
5. Confira se retornou perfis reais ou mock

## üìû Suporte

- **ScrapingDog Docs**: https://docs.scrapingdog.com/
- **LinkedIn Robots.txt**: https://www.linkedin.com/robots.txt
- **Termos de Uso**: Respeite sempre os termos do LinkedIn

## ‚öñÔ∏è Conformidade Legal

**IMPORTANTE**:
- Web scraping pode violar termos de servi√ßo
- Verifique legalidade na sua jurisdi√ß√£o
- Use apenas para fins leg√≠timos
- Respeite privacidade dos usu√°rios
- Considere usar API oficial do LinkedIn (requer aprova√ß√£o)
